{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams = pd.read_csv(\"mm_data\\MDataFiles_Stage1\\MTeams.csv\")\n",
    "reg_se_dt = pd.read_csv(\"mm_data\\MDataFiles_Stage1\\MRegularSeasonDetailedResults.csv\")\n",
    "tour_com = pd.read_csv(\"mm_data\\MDataFiles_Stage1\\MNCAATourneyCompactResults.csv\")\n",
    "rankings = pd.read_csv(\"mm_data\\MDataFiles_Stage1\\MMasseyOrdinals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_se_cm = pd.read_csv(\"mm_data\\MDataFiles_Stage1\\MRegularSeasonCompactResults.csv\")\n",
    "reg_se_cm = reg_se_cm.query('Season >= 2003')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous two blocks imports necessary packages and import the data. Data files should be placed in a folder name mm_data located at the same place with notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function defined below will be used in the next block to turn the detailed game data of seasons 2003 - 2018 into a dictionary. The function itself takes team id (id conventions are coming from the data set) and the dataset and returns several stats of given team as a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_data_col(teamid, datas):\n",
    "    #this function takes an integer input which stands for team id and exports the data information of the given team.  \n",
    "    team_data = {'teamid' : teamid}\n",
    "    team_winning_data = datas[datas.WTeamID == teamid]\n",
    "    team_losing_data = datas[datas.WTeamID == teamid]\n",
    "    team_data['win'] = team_winning_data.shape[0]\n",
    "    team_data['los'] = team_winning_data.shape[0]\n",
    "    team_data['played'] = team_data['los'] + team_data['win']\n",
    "    n = team_data.get('played')\n",
    "    team_data['score_avg'] = (team_losing_data.LScore.sum() + team_winning_data.WScore.sum())/n\n",
    "    team_data['fgoal_avg'] = (team_winning_data.WFGM.sum() + team_losing_data.LFGM.sum())/n\n",
    "    team_data['fgoal_at_avg'] = (team_winning_data.WFGA.sum() + team_losing_data.LFGA.sum())/n\n",
    "    team_data['pointer_avg'] = (team_winning_data.WFGM3.sum() + team_losing_data.LFGM3.sum())/n\n",
    "    team_data['pointer_at_avg'] = (team_winning_data.WFGA3.sum() + team_losing_data.LFGA3.sum())/n\n",
    "    team_data['off_reb_avg'] = (team_winning_data.WOR.sum() + team_losing_data.LOR.sum())/n\n",
    "    team_data['def_reb_avg'] = (team_winning_data.WDR.sum() + team_losing_data.LDR.sum())/n\n",
    "    team_data['ast_avg'] = (team_winning_data.WAst.sum() + team_losing_data.LAst.sum())/n\n",
    "    team_data['turn_avg'] = (team_winning_data.WTO.sum() + team_losing_data.LTO.sum())/n\n",
    "    team_data['stl_avg'] = (team_winning_data.WStl.sum() + team_losing_data.LStl.sum())/n\n",
    "    team_data['block_avg'] = (team_winning_data.WBlk.sum() + team_losing_data.LBlk.sum())/n\n",
    "    team_data['foul_avg'] = (team_winning_data.WPF.sum() + team_losing_data.LPF.sum())/n\n",
    "    return team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  del sys.path[0]\n",
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  \n",
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "C:\\Users\\aciha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "year_list0 = reg_se_dt.Season.unique()\n",
    "year_list = []\n",
    "for i in year_list0:\n",
    "    year_list.append('year'+str(i))\n",
    "data_by_year = {}\n",
    "for i in range(len(year_list)):\n",
    "    year_name = year_list0[i]\n",
    "    reg_se_dt_yearly = reg_se_dt[reg_se_dt.Season == year_name]\n",
    "    teams0 = np.concatenate([reg_se_dt_yearly.WTeamID.unique(),reg_se_dt_yearly.LTeamID.unique()])\n",
    "    teams1 = np.unique(teams0)\n",
    "    teams2 = teams1.tolist()\n",
    "    all_teams_data = {}\n",
    "    for j in teams2:\n",
    "        all_teams_data[j] = team_data_col(j,reg_se_dt_yearly)\n",
    "    data_by_year[year_name] = all_teams_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above turns the detailed game data of 2003 - 2018 into a dictionary. The structure of the dictionary can be seen using the following code. (I couldn't figure out why I am getting errors yet it works and I am scared to mess with it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019])\n",
      "dict_keys([1102, 1103, 1104, 1105, 1106, 1107, 1108, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1119, 1120, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1135, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1189, 1190, 1191, 1192, 1193, 1194, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1214, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1224, 1225, 1226, 1227, 1228, 1229, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1256, 1257, 1258, 1259, 1260, 1261, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1296, 1298, 1299, 1301, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1313, 1314, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1368, 1369, 1371, 1372, 1373, 1374, 1375, 1376, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1431, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464])\n",
      "dict_keys(['teamid', 'win', 'los', 'played', 'score_avg', 'fgoal_avg', 'fgoal_at_avg', 'pointer_avg', 'pointer_at_avg', 'off_reb_avg', 'def_reb_avg', 'ast_avg', 'turn_avg', 'stl_avg', 'block_avg', 'foul_avg'])\n"
     ]
    }
   ],
   "source": [
    "print(data_by_year.keys())\n",
    "print(data_by_year.get(2003).keys())\n",
    "print(data_by_year.get(2003).get(1102).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code takes tournament game results of 1985 - 2019 and returns 2003 - 2018 tournament game results. Since there is no detailed stats of the games 1985 - 2002 I don't use those games to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tour_com = tour_com.query('Season >= 2003 & Season != 2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to return teams ranking at a given year using the ranking data. The datas are given up to first day of the tournament therefore I used the last given rank of each year. Also, there are more than one rankng system hence I took the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_rank(year, teamid, data):\n",
    "    #this function takes input of year number, day number, ranking data and returns the ranking of the team at given year given date.\n",
    "    day_num =  data.loc[(data['Season'] == year) & (data['TeamID'] == teamid)].RankingDayNum.max()\n",
    "    ranks = data.loc[(data['Season'] == year) & (data['TeamID'] == teamid) & (data['RankingDayNum'] == day_num), 'OrdinalRank']\n",
    "    return ranks.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to return ratio of wins of a team at home and at away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_away(team_id,year,data):\n",
    "    data_year = data.loc[data['Season'] == year]\n",
    "    team_wins_home = len(data_year[(data_year['WTeamID'] == team_id) & (data_year['WLoc'] =='H')])\n",
    "    team_los_home = len(data_year[(data_year['WTeamID'] == team_id) & (data_year['WLoc'] =='H')])\n",
    "    team_wins_away = len(data_year[(data_year['WTeamID'] == team_id) & (data_year['WLoc'] =='A')])\n",
    "    team_los_away = len(data_year[(data_year['LTeamID'] == team_id) & (data_year['WLoc'] =='A')])\n",
    "    return team_wins_home/(team_wins_home+team_los_home), team_wins_away/(team_los_away+team_wins_away)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code uses the tournament game compact results to create a feature/labels data frame for tournament games. It uses data_by_year dictionary and team_rank and home_away function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = pd.DataFrame(columns=['game_id', 'result', 'win_diff','loss_diff', 'played_diff', 'score_av_diff','fgoal_diff', 'fgoal_at_diff', 'pointer_diff','pointer_at_diff', 'off_reb_diff', 'def_reb_diff','ast_diff', 'turn_diff', 'stl_diff','block_diff', 'foul_diff','rank1','rank2','home1', 'away1','home2', 'away2'])\n",
    "for i in range(len(tour_com)):\n",
    "    year = tour_com.Season.iloc[i]\n",
    "    win_id = tour_com.WTeamID.iloc[i]\n",
    "    los_id = tour_com.LTeamID.iloc[i]\n",
    "    win_data = data_by_year.get(year).get(win_id)\n",
    "    loss_data = data_by_year.get(year).get(los_id)\n",
    "    dice = np.round_(np.random.random(),decimals = 0)\n",
    "    data_array = []\n",
    "    if dice == 0:\n",
    "        for key in win_data.keys():\n",
    "            data_array.append(loss_data[key]-win_data[key])\n",
    "        data_array.append(team_rank(year,win_id,rankings))\n",
    "        data_array.append(team_rank(year,los_id,rankings))\n",
    "        win_home, win_away =  home_away(win_id,year,reg_se_cm)\n",
    "        los_home, los_away = home_away(los_id,year,reg_se_cm)\n",
    "        data_array = data_array + [win_home,win_away,los_home,los_away]\n",
    "        data_array[0] = 0\n",
    "    elif dice == 1:\n",
    "        for key in win_data.keys():\n",
    "            data_array.append(win_data[key]-loss_data[key])\n",
    "        data_array.append(team_rank(year,los_id,rankings))\n",
    "        data_array.append(team_rank(year,win_id,rankings))\n",
    "        win_home, win_away =  home_away(win_id,year,reg_se_cm)\n",
    "        los_home, los_away = home_away(los_id,year,reg_se_cm)\n",
    "        data_array = data_array + [los_home,los_away,win_home,win_away]\n",
    "        data_array[0] = 1\n",
    "    data_array.insert(0,i)\n",
    "    games_df.loc[len(games_df)] = data_array    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_data = games_df.drop(['game_id','result'], axis = 1)\n",
    "games_labels = games_df.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data. (Logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "softmax_reg = LogisticRegression(multi_class = \"multinomial\", solver = \"lbfgs\", C = 1, max_iter = 1000)\n",
    "softmax_reg.fit(games_data, games_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rest of the code is testing the trained model with the results of 2019 tournament. Data manipulations are exactly same with changing the year of subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tour_com_test = pd.read_csv(\"mm_data\\MDataFiles_Stage1\\MNCAATourneyCompactResults.csv\")\n",
    "tour_com_test = tour_com_test.query('Season == 2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df_2019 = pd.DataFrame(columns=['game_id', 'result', 'win_diff','loss_diff', 'played_diff', 'score_av_diff','fgoal_diff', 'fgoal_at_diff', 'pointer_diff','pointer_at_diff', 'off_reb_diff', 'def_reb_diff','ast_diff', 'turn_diff', 'stl_diff','block_diff', 'foul_diff','rank1','rank2','home1', 'away1','home2', 'away2'])\n",
    "for i in range(len(tour_com_test)):\n",
    "    win_id = tour_com_test.WTeamID.iloc[i]\n",
    "    los_id = tour_com_test.LTeamID.iloc[i]\n",
    "    win_data = data_by_year.get(2019).get(win_id)\n",
    "    loss_data = data_by_year.get(2019).get(los_id)\n",
    "    data_array = []\n",
    "    for key in win_data.keys():\n",
    "        data_array.append(loss_data[key]-win_data[key])\n",
    "    data_array.append(team_rank(year,win_id,rankings))\n",
    "    data_array.append(team_rank(year,los_id,rankings))\n",
    "    win_home, win_away =  home_away(win_id,year,reg_se_cm)\n",
    "    los_home, los_away = home_away(los_id,year,reg_se_cm)\n",
    "    data_array = data_array + [win_home,win_away,los_home,los_away]\n",
    "    data_array[0] = 0    \n",
    "    data_array.insert(0,i)\n",
    "    games_df_2019.loc[len(games_df_2019)] = data_array    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df_2019_test = games_df_2019.drop(['game_id','result'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13432835820895522"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(softmax_reg.predict(games_df_2019_test))/len(games_df_2019_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error returns 13%(was at my first run)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
