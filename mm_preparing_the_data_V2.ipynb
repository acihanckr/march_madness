{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>March Madness Tournament Games Predictor</h1>\n",
    "\n",
    "The main objective of this project is to train a predictive model using the NCAAM regular season statistics and tournament game results from 1985 through 2018 to predict the results of the games of 2019 using the regular season statistics.\n",
    "\n",
    "<h3>Data Manipulation</h3>\n",
    "\n",
    "This notebook includes the data manipulation to bring the data to the desired form. I'd like to define a feature vector for each tournament game played after 2003 through 2019 inclusive. \n",
    "\n",
    "For a given game from the tournament at a particular year, I set either the winning or the losing team as Team 1 and the other team as Team 2 randomly. I want the feature vector of the game include the following statistics of both team 1 and team 2 seperately from the regular season of the tournament game:\n",
    "\n",
    "The number of the games the team won,\n",
    "the number of the games the team lost,\n",
    "the ratio of wins at home games,\n",
    "the ratio of win at away games,\n",
    "average score per game,\n",
    "average field goal per game,\n",
    "the number of field goal attemp per game,\n",
    "the average 3 point scores per game,\n",
    "the number of 3 point attemps per game,\n",
    "the number of offensive rebounds per game,\n",
    "the number of defensive rebounds per game,\n",
    "the number of assists per game,\n",
    "the number of steals per game,\n",
    "the number of blocks per game,\n",
    "the number of personal fouls per game,\n",
    "average of the ranking of the team at the last day of the season,\n",
    "seeds if the team has any.\n",
    "\n",
    "Apart from these features which is recorded for two teams seperately I add some features which is specific for the game. These are:\n",
    "\n",
    "Results (as win or loose) of previous games between two teams if any,\n",
    "which team is the home team.\n",
    "\n",
    "Lastly, I record all the data to a csv file.\n",
    "\n",
    "Let's start importing the necessary packages and the data. Data files should be placed in a folder name mm_data located at the same place with notebook in order this code to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File mm_data\\MDataFiles_Stage1\\MRegularSeasonDetailedResults.csv does not exist: 'mm_data\\\\MDataFiles_Stage1\\\\MRegularSeasonDetailedResults.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-95750b5b89d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreg_se_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mm_data\\MDataFiles_Stage1\\MRegularSeasonDetailedResults.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtour_com\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mm_data\\MDataFiles_Stage1\\MNCAATourneyCompactResults.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrankings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mm_data\\MDataFiles_Stage1\\MMasseyOrdinals.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mm/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mm/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mm/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mm/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mm/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File mm_data\\MDataFiles_Stage1\\MRegularSeasonDetailedResults.csv does not exist: 'mm_data\\\\MDataFiles_Stage1\\\\MRegularSeasonDetailedResults.csv'"
     ]
    }
   ],
   "source": [
    "reg_se_dt = pd.read_csv(\"mm_data\\MDataFiles_Stage1\\MRegularSeasonDetailedResults.csv\")\n",
    "tour_com = pd.read_csv(\"mm_data\\MDataFiles_Stage1\\MNCAATourneyCompactResults.csv\")\n",
    "rankings = pd.read_csv(\"mm_data\\MDataFiles_Stage1\\MMasseyOrdinals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_se_cm = pd.read_csv(\"mm_data\\MDataFiles_Stage1\\MRegularSeasonCompactResults.csv\")\n",
    "seed_data = pd.read_csv('mm_data\\MDataFiles_Stage1\\MNCAATourneySeeds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first create a data frame which contains the information on each game I want to use as a data point. For each game the code decides to call either winning team 'team1' or 'team2' randomly. If team 1 is the winner of the game it labels the game 0 as the result if team 1 is the losing team it labels the game 1 as the result. This initial data frame will also include team1_id, team2_id, year of the game, the day of the game.\n",
    "\n",
    "I define the following function to create the described data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def games_data_col(years, games_data):\n",
    "    games_df = pd.DataFrame(columns=['game_year','game_day','team1_id','team2_id','result']) \n",
    "    active_games = games_data[games_data['Season'].isin(years)]\n",
    "    for i in range(len(active_games)):\n",
    "        #record the ids of winning and losing team.\n",
    "        #record the year of the game\n",
    "        year = active_games.Season.iloc[i]\n",
    "        game_day = active_games.DayNum.iloc[i]\n",
    "        win_id = active_games.WTeamID.iloc[i]\n",
    "        los_id = active_games.LTeamID.iloc[i]\n",
    "        #decide which team will be called 1. If dice gives 0 then Team 1 is winning and Team 2 is losing.\n",
    "        #if dice gives 1 then Team 2 is winning and Team1 is winning\n",
    "        dice = random.randint(0,1)\n",
    "        #create data array for the game.\n",
    "        if dice == 0:\n",
    "            data_array = [year, game_day, win_id, los_id] + [0] \n",
    "        elif dice == 1:\n",
    "            data_array = [year,game_day,los_id,win_id] + [1]\n",
    "        games_df.loc[len(games_df)] = data_array\n",
    "        clear_output(wait= True)\n",
    "        print('%' + str(round(i/len(active_games)*100,0))+' Completed')\n",
    "    games_df['result'] = games_df['result'].astype(int)\n",
    "    return games_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I call the previous function for the tournament games between 2003-2019 (both included). I called this data frame game information and features data frame or GIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gif = games_data_col(range(2003,2020),tour_com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is defined to add two new feature columns to the GIF. Columns represent the same statistics for team1 and team 2 competing. It accepts 4 argument: \n",
    "\n",
    "- feat_name: the name of the new column\n",
    "- df:data frame to update\n",
    "- source_data: the data frame which the team statistics will be collected from\n",
    "- stat_col: a function which to extract the data for each team from source data\n",
    "    \n",
    "It returns the updated data frame.\n",
    "\n",
    "<h3>Remark:</h3>I should say this is definitely not the fastest way to transform the data. It is actually quite slower than my previous tries. The main reason I am following this strategy is seperating the statistic collector functions from row by row modification of the data frame I can re-use these functions for other sets of data points or similar data collection precuders with small adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function has three seperate main features. If the input count is not given then the function assumes it is called for a tournament game and it collects the statistics from the (whole) regular season of the tournament year. In this case the function only passes the this year's data to the data collector.\n",
    "\n",
    "If count=n is a positive integer then it finds n many previous games of the given team and collects the same statistics for those games. I modified the function to use it for regular season games in a reasonable way. In this case the function is passing only last n games data to the statistics collector.\n",
    "\n",
    "If the count is -1 then it the function passes all data to the data collector and the data collector should decide which portions of the data will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_a_feat(stat_col,df,feat_name,data,count=0):\n",
    "    if count == 0:\n",
    "        feat1 = feat_name + str(1)\n",
    "        feat2 = feat_name + str(2)\n",
    "        df[feat1] = np.nan\n",
    "        df[feat2] = np.nan\n",
    "        for i in range(len(df)):\n",
    "            year = df.game_year.loc[i]\n",
    "            data_adj = data.loc[data['Season']==year]\n",
    "            df.at[i,feat1] = stat_col(df.team1_id.loc[i],data_adj)\n",
    "            df.at[i,feat2] = stat_col(df.team2_id.loc[i],data_adj)\n",
    "            clear_output(wait= True)\n",
    "            print('%' + str(round(i/len(df)*100,0))+' Completed')\n",
    "        return df\n",
    "    elif count == -1:\n",
    "        feat1 = feat_name + str(1)\n",
    "        feat2 = feat_name + str(2)\n",
    "        df[feat1] = np.nan\n",
    "        df[feat2] = np.nan\n",
    "        for i in range(len(df)):\n",
    "            df.at[i,feat1] = stat_col(df.game_year.loc[i],df.team1_id.loc[i],data)\n",
    "            df.at[i,feat2] = stat_col(df.game_year.loc[i],df.team2_id.loc[i],data)\n",
    "            clear_output(wait= True)\n",
    "            print('%' + str(round(i/len(df)*100,0))+' Completed')\n",
    "        return df\n",
    "    else:\n",
    "        feat1 = feat_name + str(1)\n",
    "        feat2 = feat_name + str(2)\n",
    "        df[feat1] = np.nan\n",
    "        df[feat2] = np.nan\n",
    "        for i in range(len(df)):\n",
    "            team1 = df.team1_id.loc[i]\n",
    "            team2 = df.team2_id.loc[i]\n",
    "            year = df.game_year.loc[i] \n",
    "            day = df.game_day.loc[i]\n",
    "            data_adj1 = data.loc[((data['WTeamID'] == team1) | (data['LTeamID'] == team1)) & (data['Season'] <= year) & (data['DayNum'] < day)]\n",
    "            data_adj1 = data_adj1.tail(count)\n",
    "            if len(data_adj1)>=count:\n",
    "                df.at[i,feat2] = stat_col(team2,data_adj2)    \n",
    "            data_adj2 = data.loc[((data['WTeamID'] == team2) | (data['LTeamID'] == team2)) & (data['Season'] <= year) & (data['DayNum'] < day)]\n",
    "            data_adj2 = data_adj2.tail(count)\n",
    "            if len(data_adj2)>=count:\n",
    "                df.at[i,feat1] = stat_col(team1,data_adj1)\n",
    "            clear_output(wait= True)\n",
    "            print('%' + str(round(i/len(df)*100,0))+' Completed')\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use the previous function to add new feature columns to the GIF. The following four functions are used to extract the following statistics of a given team on a given data.\n",
    "\n",
    "<ul>\n",
    "<li>win_game_stat: games won/games played (on the regular season of the given year). </li>\n",
    "<li> loss_game_stat: games lost/games played (on the regular season of the given year).</li>\n",
    "<li> home_stat: games won at home/games played at home (on the regular season of the given year)(not every game has the info on if the home team won therefore this statistics represent the known cases only).</li>    \n",
    "<li> away_stat: games won at away/games played away (on the regular season of the given year)(not every game has the info on if the home team won therefore this statistics represent the known cases only).</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_game_stat(teamid,data):\n",
    "    return len(data[(data.WTeamID == teamid)])\n",
    "def loss_game_stat(teamid,data):\n",
    "    return len(data[(data.LTeamID == teamid)])\n",
    "def home_stat(teamid,data):\n",
    "    team_wins_home = len(data[(data['WTeamID'] == teamid) & (data['WLoc'] =='H')])\n",
    "    team_los_home = len(data[(data['LTeamID'] == teamid) & (data['WLoc'] =='A')])\n",
    "    if team_wins_home+team_los_home == 0:\n",
    "        return\n",
    "    return team_wins_home/(team_wins_home+team_los_home)\n",
    "def away_stat(teamid,data):\n",
    "    team_wins_away = len(data[(data['WTeamID'] == teamid) & (data['WLoc'] =='A')])\n",
    "    team_los_away = len(data[(data['LTeamID'] == teamid) & (data['WLoc'] =='H')])\n",
    "    if team_los_away+team_wins_away == 0:\n",
    "        return\n",
    "    return team_wins_away/(team_los_away+team_wins_away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = add_a_feat(win_game_stat,gif,'win',reg_se_dt)\n",
    "gif = add_a_feat(loss_game_stat,gif,'loss',reg_se_dt)\n",
    "gif = add_a_feat(home_stat,gif,'home_win',reg_se_cm)\n",
    "gif = add_a_feat(away_stat,gif,'away_win',reg_se_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function records the ranking of a given team on a given year, in the last day of the regular season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_year0(teamid,data):\n",
    "    rank_day = data[(data['TeamID']==teamid)].RankingDayNum.max()\n",
    "    return data[(data['TeamID']==teamid) & (data['RankingDayNum']==rank_day)].OrdinalRank.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = add_a_feat(rank_year0,gif,'rank_year0',rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two functions extracts the score average of a team and the score average of team allowed from the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_stat(teamid,data):\n",
    "    win_game_score = data[(data.WTeamID == teamid)].WScore.sum()\n",
    "    lose_game_score = data[(data.LTeamID == teamid)].LScore.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_game_score+lose_game_score)/total_game\n",
    "def score_against_stat(teamid,data):\n",
    "    win_game_score = data[(data.WTeamID == teamid)].LScore.sum()\n",
    "    lose_game_score = data[(data.LTeamID == teamid)].WScore.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_game_score+lose_game_score)/total_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = add_a_feat(score_stat,gif,'score_av',reg_se_dt)\n",
    "gif = add_a_feat(score_against_stat,gif,'score_ag_av',reg_se_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following four functions are used to extract the following statistics of a given team on a given data:\n",
    "\n",
    "\n",
    "- fscore_stat: field score average of the team in given data. \n",
    "- pscore_stat: 3 pointer average of the team in given data.\n",
    "- fscore_against_stat: field score average the team allowed in the given data.    \n",
    "- pscore_against_stat: 3 pointer average the team allowed in the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fscore_stat(teamid,data):\n",
    "    win_fscore = data[(data.WTeamID == teamid)].WFGM.sum()\n",
    "    lose_fscore = data[(data.LTeamID == teamid)].LFGM.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_fscore+lose_fscore)/total_game\n",
    "def pscore_stat(teamid,data):\n",
    "    win_pscore = data[(data.WTeamID == teamid)].WFGM3.sum()\n",
    "    lose_pscore = data[(data.LTeamID == teamid)].LFGM3.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_pscore+lose_pscore)/total_game\n",
    "def fscore_against_stat(teamid,data):\n",
    "    win_fscore = data[(data.WTeamID == teamid)].LFGM.sum()\n",
    "    lose_fscore = data[(data.LTeamID == teamid)].WFGM.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_fscore+lose_fscore)/total_game\n",
    "def pscore_against_stat(teamid,data):\n",
    "    win_pscore = data[(data.WTeamID == teamid)].LFGM3.sum()\n",
    "    lose_pscore = data[(data.LTeamID == teamid)].WFGM3.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_pscore+lose_pscore)/total_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = add_a_feat(fscore_stat,gif,'field_score', reg_se_dt)\n",
    "gif = add_a_feat(pscore_stat,gif,'3pointer_score', reg_se_dt)\n",
    "gif = add_a_feat(fscore_against_stat, gif, 'field_score_ag', reg_se_dt)\n",
    "gif = add_a_feat(pscore_against_stat, gif, '3pointer_score_ag', reg_se_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three functions are used to extract the following statistics of a given team on a given data:\n",
    "\n",
    "- asist_stat: asist average of the team in given data. \n",
    "- pfoul_stat: personal foul average of the team in given data.\n",
    "- turn_over_stat: turnover average of the team in given data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asist_stat(teamid,data):\n",
    "    win_ast = data[(data.WTeamID == teamid)].WAst.sum()\n",
    "    lose_ast = data[(data.LTeamID == teamid)].LAst.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_ast+lose_ast)/total_game\n",
    "def pfoul_stat(teamid,data):\n",
    "    win_pfoul = data[(data.WTeamID == teamid)].WPF.sum()\n",
    "    lose_pfoul = data[(data.LTeamID == teamid)].LPF.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_pfoul+lose_pfoul)/total_game\n",
    "def turn_over_stat(teamid,data):\n",
    "    win_turn_over = data[(data.WTeamID == teamid)].WTO.sum()\n",
    "    loss_turn_over = data[(data.LTeamID == teamid)].LTO.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_turn_over+loss_turn_over)/total_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = add_a_feat(asist_stat,gif,'asists',reg_se_dt)\n",
    "gif = add_a_feat(pfoul_stat,gif,'personal_fouls',reg_se_dt)\n",
    "gif = add_a_feat(turn_over_stat,gif,'turn_overs',reg_se_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following four functions are used to extract the following statistics of a given team on a given data:\n",
    "\n",
    "- block_stat: block average of the team in given data. \n",
    "- def_rb_stat: defansive rebound average of the team in given data.\n",
    "- off_rb_stat: offensive rebound average of the team in given data.\n",
    "- steal_stat: steals average of the team in the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_stat(teamid,data):\n",
    "    win_block = data[(data.WTeamID == teamid)].WBlk.sum()\n",
    "    lose_block = data[(data.LTeamID == teamid)].LBlk.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_block+lose_block)/total_game\n",
    "def def_rb_stat(teamid,data):\n",
    "    win_def_rb = data[(data.WTeamID == teamid)].WDR.sum()\n",
    "    lose_def_rb = data[(data.LTeamID == teamid)].LDR.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_def_rb+lose_def_rb)/total_game\n",
    "def off_rb_stat(teamid,data):\n",
    "    win_off_rb = data[(data.WTeamID == teamid)].WOR.sum()\n",
    "    lose_off_rb = data[(data.LTeamID == teamid)].LOR.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_off_rb+lose_off_rb)/total_game\n",
    "def steal_stat(teamid,data):\n",
    "    win_stl = data[(data.WTeamID == teamid)].WStl.sum()\n",
    "    lose_stl = data[(data.LTeamID == teamid)].LStl.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_stl+lose_stl)/total_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = add_a_feat(block_stat,gif,'blocks',reg_se_dt)\n",
    "gif = add_a_feat(steal_stat,gif,'steals',reg_se_dt)\n",
    "gif = add_a_feat(def_rb_stat,gif,'defansive_rebound',reg_se_dt)\n",
    "gif = add_a_feat(off_rb_stat,gif,'offensive_rebound',reg_se_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following four functions are used to extract the following statistics of a given team on a given data:\n",
    "\n",
    "- block_ag_stat: block average the team allowed in given data. \n",
    "- def_rb_ag_stat: defansive rebound average the team allowed in given data.\n",
    "- off_rb_ag_stat: offensive rebound average the team allowed in given data.\n",
    "- steal_ag_stat: steals average the team allowed in the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_ag_stat(teamid,data):\n",
    "    win_block = data[(data.WTeamID == teamid)].LBlk.sum()\n",
    "    lose_block = data[(data.LTeamID == teamid)].WBlk.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_block+lose_block)/total_game\n",
    "def def_rb_ag_stat(teamid,data):\n",
    "    win_def_rb = data[(data.WTeamID == teamid)].LDR.sum()\n",
    "    lose_def_rb = data[(data.LTeamID == teamid)].WDR.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_def_rb+lose_def_rb)/total_game\n",
    "def off_rb_ag_stat(teamid,data):\n",
    "    win_off_rb = data[(data.WTeamID == teamid)].LOR.sum()\n",
    "    lose_off_rb = data[(data.LTeamID == teamid)].WOR.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_off_rb+lose_off_rb)/total_game\n",
    "def steal_ag_stat(teamid,data):\n",
    "    win_stl = data[(data.WTeamID == teamid)].LStl.sum()\n",
    "    lose_stl = data[(data.LTeamID == teamid)].WStl.sum()\n",
    "    total_game = len(data[(data.WTeamID == teamid) | (data.LTeamID == teamid)])\n",
    "    return (win_stl+lose_stl)/total_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = add_a_feat(block_ag_stat,gif,'blocks_ag',reg_se_dt)\n",
    "gif = add_a_feat(steal_ag_stat,gif,'steals_ag',reg_se_dt)\n",
    "gif = add_a_feat(def_rb_ag_stat,gif,'defansive_rebound_ag',reg_se_dt)\n",
    "gif = add_a_feat(off_rb_ag_stat,gif,'offensive_rebound_ag',reg_se_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_stat(teamid,data):\n",
    "    team_data = data[(data.TeamID == teamid)]\n",
    "    if len(team_data)==0:\n",
    "        return 17\n",
    "    elif len(team_data)>=2:\n",
    "        print('there are two seperate seeds for a team')\n",
    "        return\n",
    "    rank_str = team_data['Seed'].iloc[0]\n",
    "    digits = [i for i in rank_str if i.isdigit()]\n",
    "    digits_str = ''\n",
    "    for i in digits:\n",
    "        digits_str += i\n",
    "    return int(digits_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gif = add_a_feat(seed_stat,gif,'seeds',seed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three functions are used to extract the following statistics of a given team on a given data for a given year:\n",
    "\n",
    "- last_tour_wins: how many games the team won in the last year's tournament. \n",
    "- last_year_played: how many games the team played in the last year's tournament.\n",
    "- last_year_level: which level the team got up to last year.\n",
    "\n",
    "These functions need tournament compact results in order to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_tour_wins(year,teamid, data):\n",
    "    year-=1\n",
    "    win_game_ct = len(data[(data.Season == year) & (data.WTeamID == teamid)])\n",
    "    return win_game_ct\n",
    "def last_year_played(year,teamid,data):\n",
    "    year-=1\n",
    "    return len(data[(data.Season == year) & ((data.WTeamID == teamid) | (data.LTeamID == teamid))])\n",
    "def last_year_level(year,teamid,data):\n",
    "    winning = data[(data.Season == year-1) & (data.WTeamID == teamid)].LTeamID\n",
    "    losing = data[(data.Season == year-1) & (data.LTeamID == teamid)].WTeamID\n",
    "    return len(pd.concat([winning,losing]).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gif = add_a_feat(last_tour_wins,gif,\"wins_last_tour\",tour_com,-1)\n",
    "gif = add_a_feat(last_year_played,gif,\"played_last_tour\",tour_com,-1)\n",
    "gif = add_a_feat(last_year_level,gif,\"highest_level_last_tour\",tour_com,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function collects the previous games between two teams from last two regular season and current regular season and last three tournament. Then counts the wins and losses. Team 2 winnig +1 and team winnig -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_prev(df):\n",
    "    df['previous_results']=np.nan\n",
    "    for i in range(len(df)):\n",
    "        year = df.at[i,'game_year']\n",
    "        team1 = df.at[i,'team1_id']\n",
    "        team2 = df.at[i,'team2_id']\n",
    "        com_count = 0\n",
    "        com_count += len(reg_se_cm[(reg_se_cm.Season.isin(range(year-2,year+1))) & (reg_se_cm.WTeamID == team2) & (reg_se_cm.LTeamID == team1)])\n",
    "        com_count -= len(reg_se_cm[(reg_se_cm.Season.isin(range(year-2,year+1))) & (reg_se_cm.WTeamID == team1) & (reg_se_cm.LTeamID == team2)])\n",
    "        com_count += len(tour_com[(tour_com.Season.isin(range(year-3,year))) & (tour_com.WTeamID == team2) & (tour_com.LTeamID == team1)])\n",
    "        com_count -= len(tour_com[(tour_com.Season.isin(range(year-3,year))) & (tour_com.WTeamID == team1) & (tour_com.LTeamID == team2)])\n",
    "        df.at[i,'previous_results'] = com_count\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = add_prev(gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gif.to_csv('game_data.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
